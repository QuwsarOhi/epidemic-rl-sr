{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dashboard.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qz9_r5AusxjF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "outputId": "69a06db1-4f1c-4b11-c58a-d437d6d19eba"
      },
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "import time\n",
        "from math import ceil\n",
        "import random\n",
        "from glob import glob\n",
        "\n",
        "import sys, os, warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '4' \n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from agent_environment import *\n",
        "\n",
        "import seaborn as sns\n",
        "sns.set_style(\"whitegrid\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-bda35105dcb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0magent_environment\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'agent_environment'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDBbS8astDPs",
        "colab_type": "text"
      },
      "source": [
        "### Loading agent weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wP07FmBCs57x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "32e7fc46-db94-4c48-ed27-e1c1b48f4c32"
      },
      "source": [
        "agent = DQN(input_shape=(30, 7), action_size=3, batch_size=128, UPDATE_TARGET=4,\n",
        "            DISCOUNT=0.9, DISCOUNT_DECAY=0, timestep=31, REPLAY_MEM_SZ=2000) \n",
        "\n",
        "model_path = os.path.join(os.path.realpath('.'), 'base_model')\n",
        "if os.path.exists(model_path) == False:\n",
        "    print('Trained model not found')\n",
        "\n",
        "agent.model = tf.keras.models.load_model(model_path)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-210ec6c66917>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m agent = DQN(input_shape=(30, 7), action_size=3, batch_size=128, UPDATE_TARGET=4,\n\u001b[0m\u001b[1;32m      2\u001b[0m             DISCOUNT=0.9, DISCOUNT_DECAY=0, timestep=31, REPLAY_MEM_SZ=2000) \n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrealpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'base_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'DQN' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTvIojNgtOGP",
        "colab_type": "text"
      },
      "source": [
        "### Starting environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AanU75hztLoc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#1000 = 224 x 224\n",
        "#5000 = 500 x 500\n",
        "#10000 = 708 x 708\n",
        "#population_density = 0.02\n",
        "\n",
        "# Modify the seed_list to generate different random-environmental states\n",
        "env_actions = ['no-lockdown', 'semi-lockdown', 'lockdown', 'agent']\n",
        "envSetups = [{'height':577 , 'population':10000, 'seed':1, 'infected':70},\n",
        "            {'height':708 , 'population':10000, 'seed':6, 'infected':70},\n",
        "            {'height':1000 , 'population':10000, 'seed':4, 'infected':70}]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BteSxdatNQ5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "70e41b68-51f9-476b-e783-407bfa9844f0"
      },
      "source": [
        "for envSetup in envSetups:\n",
        "    for act in env_actions:\n",
        "        print('Starting environ with the parameters', envSetup)\n",
        "        print('The actions are based on', act)\n",
        "\n",
        "        env = Env(height=envSetup['height'], width=envSetup['height'], \n",
        "                  population=envSetup['population'], \n",
        "                  infected_ratio=0.002, beta=np.inf, prob=1, boundary=0, \n",
        "                  cure_after=21, infect_after=2, death_distribution=[0.2, 0.8], \n",
        "                  day_step=15, day_limit=0, normalize=True, linear_reward=False)\n",
        "\n",
        "        done = False\n",
        "        tot_reward, actions, real_act = 0, 0, 0\n",
        "        st = time.time()\n",
        "        data = {'Day': [], 'R0': [], 'Active Cases': [], 'Infected': [], \n",
        "                'Economy': [], 'Death': [], 'Cured': [], \n",
        "                'Action': [], 'Population': env.population, 'R00': [], \n",
        "                'Reward': [], 'Action1': [], 'Action2': [], 'Action3': []} \n",
        "\n",
        "        agent.initReplay()\n",
        "\n",
        "        # Manually setting the number of infected population\n",
        "        env.first_infected = envSetup['infected']\n",
        "\n",
        "        current_state = np.array(list(env.reset(envSetup['seed']))+[0], dtype=np.float32)\n",
        "        cycle_count = 0\n",
        "        best_action = 0\n",
        "\n",
        "        while not done:\n",
        "            if act == 'agent':\n",
        "                reward_preds = agent.get_qs(current_state)\n",
        "                best_action = np.argmax(reward_preds)\n",
        "                data['Action1'].append(reward_preds[0, 0])\n",
        "                data['Action2'].append(reward_preds[0, 1])\n",
        "                data['Action3'].append(reward_preds[0, 2])\n",
        "            if act == 'lockdown':\n",
        "                best_action = 2\n",
        "            if act == 'semi-lockdown':\n",
        "                best_action = 1\n",
        "            if act == 'no-lockdown':\n",
        "                best_action = 0\n",
        "            \n",
        "            data['Day'].append(env.log['day'])\n",
        "            data['Active Cases'].append(env.log['active_cases'])\n",
        "            data['Infected'].append(env.log['infected'])\n",
        "            data['Cured'].append(env.log['cured'])\n",
        "            data['Economy'].append(env.log['economy'])\n",
        "            data['R0'].append(env.log['R0'])\n",
        "            data['R00'].append(env.log['R00'])\n",
        "            data['Death'].append(env.log['death'])\n",
        "            data['Action'].append(best_action)\n",
        "    \n",
        "            # Perform the action\n",
        "            new_state, reward, done, dct = env.step(best_action)\n",
        "            new_state = np.array(list(new_state)+[best_action], dtype=np.float32)\n",
        "            data['Reward'].append(reward)\n",
        "    \n",
        "            # Find the q values of the new state (after performing previous action)\n",
        "            tot_reward += reward\n",
        "    \n",
        "            agent.update_replay_memory((current_state, best_action, reward, new_state, done))\n",
        "            #agent.train(done, actions)\n",
        "            current_state = new_state\n",
        "            print(f\"\\rDay:{data['Day'][-1]}, R0:{data['R0'][-1]:0.1f}, Infected:{data['Infected'][-1]}, AC:{data['Active Cases'][-1]}\", end='')\n",
        "        \n",
        "        rl = len(data['Reward'])\n",
        "        data['RewardSum'] = [x for x in data['Reward']]\n",
        "        for i in range(rl-2, -1, -1):\n",
        "            data['RewardSum'][i] += data['Reward'][i+1]*agent.DISCOUNT\n",
        "        data['Total Infected'] = env.total_infected\n",
        "        data['Total Cured'] = env.total_cured\n",
        "        data['Total Death'] = env.total_death\n",
        "        data['Total Economy'] = np.sum(data['Economy'])\n",
        "        data['MAX_ECONOMY'] = env.observation_space_high[2]\n",
        "        data['TOTAL_POPULATION'] = env.observation_space_high[1]\n",
        "        \n",
        "        draw(data, rewards=False, plot=False, \n",
        "            #title=f\"Population: {env.population}, Initial Infectious: {infpop}\",\n",
        "            filename=os.path.join(os.path.realpath('.'), \n",
        "                                  \"dashboard_logs\", \n",
        "                                  f\"{env.height}_{env.population}_{envSetup['seed']}_{envSetup['infected']}_{act}\")\n",
        "            )\n",
        "        print('Log saved in dashboard_logs')\n",
        "        #actionvals.append(np.sum(data['Reward']))\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting environ with the parameters {'height': 577, 'population': 10000, 'seed': 1, 'infected': 70}\n",
            "The actions are based on no-lockdown\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-5d5d86644dbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The actions are based on'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         env = Env(height=envSetup['height'], width=envSetup['height'], \n\u001b[0m\u001b[1;32m      7\u001b[0m                   \u001b[0mpopulation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menvSetup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'population'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                   \u001b[0minfected_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.002\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboundary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Env' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9A40oOvtWCR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}