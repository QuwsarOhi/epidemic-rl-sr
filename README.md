## Exploring Optimal Control of Epidemic Spread Using Reinforcement Learning

#### Authors: Abu Quwsar Ohi, M. F. Mridha, Muhammad Mostafa Monowar, and Md. Abdul Hamid

##### This is an implementation of the FruitDet. A jupyter notebook version and a python version is attached in the repo.

The paper is peer-reviewed and published in Scientific Reports.

Paper link: https://doi.org/10.1038/s41598-020-79147-8

## Environment & Challenge

Through a pandemic situation, the foremost intention is to produce a vaccine that provides immunity over a particular infectious disease. However, an effective vaccine may take years to develop depending on the disease and some certain criteria. While investigating the vaccine, the loss of a pandemic is to be controlled via proper clinical support and by reducing the expanse of the disease. Nevertheless, assuring proper clinical care is not possible in a pandemic situation due to a large number of infections over the available limited clinical support. Therefore, lessening the expanse of a disease is the first and foremost effort to overcome the devastation of a pandemic disaster.

Pandemics are often caused by diseases that transmit through person-to-person close contact. At present, pandemics are caused by flu such as Swine flu, and Coronavirus. Different intervention means are proven to reduce the devastation of a pandemic outbreak. However, these interventions often cause an economic breakdown, and it is not possible to reduce the impact of a pandemic without it. Therefore, a pandemic situation raises challenges to balance the viral spread and a steady economy.

![environment](https://github.com/QuwsarOhi/epidemic-rl-sr/blob/1eb7ef7652a75b1639ab49a17fdaef76737567e2/imgs/infograph_trans.png)

## Implementation

The overall script is implemented using Python-3.

The package requirenment are given in the "requirenments.txt" file.
Please execute "pip install -r requirenments.txt" to install the necessary packages.

The discription of the each file/folders are given below:

- **requirenments.txt:**     Contains necessary package/library names
- **agent_environment.py:** Contains the algorithm/implementation of the Virtual 
                          Environment, Agent, and necessary graph visualization 
                          implementations.
- **agent_training.py:**     Contains script to train an Agent using the Virtual 
                          Environment. Executing the script will further train a 
                          new agent. The new agent (along with the training variables) 
                          are repeteadly saved after 10 episodes in the "saved_params" 
                          folder. 
- **dashboard.py:**          Contains script that is used to generate graphs that 
                          visualize the environment and the actions performed by 
                          the agent. We used this script to generate the results of 
                          the agent. The script uses the model weights defined in the 
                          "base_model" directory.
- **base_model:**            The directory contains a TensorFlow generated Keras weights. 
                          The weights are generated through our training process defined 
                          in the paper.
- **train_logs:**            The directory contains a graphical report generated by the script 
                          "agent_training.py".
- **saved_params:**          The directory contains parameters and agent weights while executing 
                          the "agent_training.py" script. Erasing all files from this directory 
                          will cause the training to start from the beginning (Episode 1).
- **dashboard_logs:**        Contains graphical reports generated by the "dashboard.py" script.
